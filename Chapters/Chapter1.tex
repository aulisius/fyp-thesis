% Chapter 1

\chapter{INTRODUCTION} % Write in your own chapter title All Chapter headings in CAPS
\section{LLVM} % All Section headings in Title Case
Low Level Virtual Machine(LLVM)\cite{Lattner:2004:LCF:977395.977673} is a compiler framework designed to support transparent, lifelong program analysis and transformation for arbitrary programs, by providing high-level information to compiler transformations at compile-time, link-time, run-time, and in idle time between runs. LLVM defines a common, low-level code representation in Static Single Assignment (SSA) form, and uses a universal Intermediate representation (IR) for representing code at a level slightly above the assembly code. LLVM has matured into a full fledged compilation ecosystem with Clang being an excellent multi-stage optimizing compiler that can be a drop in replacement for GCC. We aim to implement Predictive commoning, a kind of loop optimization, in the LLVM compiler infrastructure.

\section{Need for the system}
LLVM applies loop optimizations to the generated IR, as a part of the optimization passes run by default. They include Loop Deletion, Loop extract, Loop reduce, Loop rotate, Loop Unroll, Loop unswitch and Loop simplify. However, LLVM does not apply optimization for loops in any predictive manner. While it's GCC counterpart applies the predictive commoning, LLVM applies no such optimization. We implement second order predictive commoning to the LLVM infrastructure as a loadable module which can be invoked using a special flag.

\section{Project Overview} %All Sub Section headings in Title Case
 The project is divided into two main modules. The first module involves the Computations reuse phase, with sub modules including Detecting indexing sequences and Re-associating expressions. The second module deals with the Loop unroll phase, with Unroll factor calculation, Register preparation for copying and Unroll the actual loop.
  The first module annotates the LLVM IR that needs to be optimized, and marks them with required tags. We run through the IR code, find the basic blocks with loops and iterate through them, looking at all the GetElementPtr(GEP) instructions inside the loop bodies. The loads before and after GEP instructions are classified into dominant and dominated loads. We also classify them into LHS and RHS expressions, and only RHS expressions are marked for optimization. Further optimization is done in the second pass.
  
  The second module deals with creation of a new basic block, hoisting of the annotated instructions outside the loop. 